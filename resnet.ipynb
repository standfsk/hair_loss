{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋에 적용할 transform\n",
    "transform = Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "# 데이터 경로\n",
    "data_path = 'data'\n",
    "# split_data(data_path)\n",
    "\n",
    "# 주요 하이퍼 파라미터\n",
    "learning_rate = 0.0001\n",
    "batch_size = 32\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epoch_num = 100\n",
    "\n",
    "# Train 데이터셋 및 DataLoader 생성\n",
    "train_dataset = datasets.ImageFolder(f'{data_path}/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Validation 데이터셋 및 DataLoader 생성\n",
    "val_dataset = datasets.ImageFolder(f'{data_path}/val', transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Test 데이터셋 및 DataLoader 생성\n",
    "test_dataset = datasets.ImageFolder(f'{data_path}/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.c2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x_ = x\n",
    "        \n",
    "        x = self.c1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.c2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x_ = self.downsample(x_)\n",
    "        \n",
    "        x += x_\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
    "        self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
    "        self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
    "        \n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=64*56*56, out_features=2048)\n",
    "        self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
    "        self.fc3 = nn.Linear(in_features=512, out_features=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.b1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_val_loss - self.min_delta:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True \n",
    "\n",
    "# 모델 학습 결과 csv 파일로 저장              \n",
    "def save_metrics(mode, output_dir, epoch, loss, accuracy):\n",
    "    csv_file = f'{output_dir}/{mode}_metrics.csv'\n",
    "    if not os.path.exists(csv_file):\n",
    "        with open(csv_file, 'w') as csvfile:\n",
    "            fieldnames = ['epoch', 'loss', 'accuracy']\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(fieldnames)\n",
    "            writer.writerow([epoch, loss, accuracy])\n",
    "    else:\n",
    "        with open(csv_file, 'a') as csvfile:\n",
    "            fieldnames = ['epoch', 'loss', 'accuracy']\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([epoch, loss, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = ResNet()\n",
    "# model.to(device)\n",
    "# # 모델 요약\n",
    "# summary(model, (3, 224, 224), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 시간 설정\n",
    "train_start_time = time.time()\n",
    "\n",
    "# 모델 선언\n",
    "model = ResNet()\n",
    "model.to(device)\n",
    "# 모델 경로 설정\n",
    "model_pth = 'model_result'\n",
    "# optimizer 설정\n",
    "optim = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# earlystopping 설정\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.005)\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# csv 파일 저장\n",
    "train_metrics_file = 'train_metrics.csv'\n",
    "validation_metrics_file = 'validation_metrics.csv'\n",
    "with open(os.path.join(model_pth,train_metrics_file), 'w', newline='') as train_file, open(os.path.join(model_pth,validation_metrics_file), 'w', newline='') as val_file:\n",
    "    train_writer = csv.writer(train_file)\n",
    "    val_writer = csv.writer(val_file)\n",
    "    train_writer.writerow(['Epoch', 'Train Loss', 'Train Accuracy'])\n",
    "    val_writer.writerow(['Epoch', 'Validation Loss', 'Validation Accuracy'])\n",
    "\n",
    "# Train   \n",
    "for epoch in tqdm(range(epoch_num)):\n",
    "    model.train()\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    for data, label in train_loader:\n",
    "        optim.zero_grad()\n",
    "        preds = model(data.to(device)).squeeze(dim=1)\n",
    "        label = label.float()\n",
    "        loss = nn.BCELoss()(preds, label.to(device))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Train accuracy 계산\n",
    "        predicted_train = (preds > 0.5).int()\n",
    "        total_train += label.size(0)\n",
    "        correct_train += (predicted_train == label.to(device)).sum().item()\n",
    "    # total_accuracy 계산\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    # train 결과 저장\n",
    "    save_metrics('train', model_pth, epoch+1, loss.item(), train_accuracy)\n",
    "    # 모델 weights 저장\n",
    "    torch.save(model.state_dict(), f'{model_pth}/ResNet{epoch+1}.pt')\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, label in val_loader:\n",
    "            preds = model(data.to(device)).squeeze(dim=1)\n",
    "            label = label.float()\n",
    "            val_loss += nn.BCELoss()(preds, label.to(device)).item()\n",
    "            predicted = (preds > 0.5).int()\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label.to(device)).sum().item()\n",
    "            \n",
    "    # Validation accuracy와 loss 계산\n",
    "    val_loss /= len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    # Validation 결과 저장\n",
    "    save_metrics('validation', model_pth, epoch+1, val_loss, accuracy)\n",
    "\n",
    "    # Early Stopping\n",
    "    if early_stopping(val_loss):\n",
    "        print('Early stopping triggered!')\n",
    "        break\n",
    "\n",
    "# 총 학습시간 기록    \n",
    "print(f'training duration: {time.time()-train_start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 load\n",
    "model.load_state_dict(torch.load(f'{model_pth}/ResNet_best.pt'))\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        preds = model(data.to(device)).squeeze(dim=1)\n",
    "        label = label.float()\n",
    "        test_loss += nn.BCELoss()(preds, label.to(device)).item()\n",
    "        predicted = (preds > 0.5).int()\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label.to(device)).sum().item()\n",
    "\n",
    "# Test accuracy와 loss 계산\n",
    "test_loss /= len(test_loader)\n",
    "accuracy = 100 * correct / total\n",
    "# Test 결과 기록\n",
    "print(f'Test loss: {test_loss}, Test Accuracy: {accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
